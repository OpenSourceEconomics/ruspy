{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from ruspy.estimation.criterion_function import get_criterion_function\n",
    "from ruspy.simulation.simulation import simulate\n",
    "from ruspy.model_code.fix_point_alg import calc_fixp\n",
    "from ruspy.model_code.cost_functions import lin_cost\n",
    "from ruspy.model_code.cost_functions import calc_obs_costs\n",
    "from ruspy.estimation.estimation_transitions import create_transition_matrix\n",
    "from auxiliary_iskhakov import check_simulated_data\n",
    "from estimagic import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Replication of Iskhakov et al. (2016)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we seek to replicate Iskhakov et al. (2016) with some notable differences in the setup which we will explain in the course of this notebook. Before making your way through this notebook it is advisable to first have a look at the [other replication notebook](https://github.com/OpenSourceEconomics/ruspy/blob/master/docs/source/tutorials/replication/replication.ipynb) to get you started on how to use the ruspy package. \n",
    "\n",
    "To familiarize you with the set up in the paper let us start with a few key points to understand the remainder. Iskhakov et al. (2016) follow up on Su and Judd (2012) in which they had compared the performance of Mathematical Programming with Equlibrium Constraints (MPEC) and the Nested Fixed Point Algorithm (NFXP) for the canonical structural model of bus engine replacement based on Rust (1987). The aim of Iskhakov et al. is mainly to improve the setup of the NFXP of Su and Judd following the explanations of Rust (2000). Their revised comparison between MPEC and NFXP shows that both approaches perform similarly for a Monte Carlo simulation of the bus engine replacement problem. \n",
    "\n",
    "We replicate parts of this Monte Carlo simulation below using our ruspy package in which we have implemented MPEC as well as the NFXP in pure Python. This is gives us the flexibility to easily experiment with key assumptions such as tolerance or optimization algorithms used in one common interface. \n",
    "\n",
    "In the boxes just below we obtain all the key results needed to replicate Table I of Iskhakov et al. For that we simulate the data using the ruspy package and based on the data generating process described in Iskhakov et al. (2016). There they use the setup in which we have 120 time periods and 50 buses. The cost function is assumed to be linear taking the following form $c(x, \\theta_1) = 0.001 \\theta_{11} x$. The true parameters are the following: \n",
    "\n",
    "\\begin{equation}\n",
    "RC=11.7257,  \\\\\n",
    "\\theta_{11}=2.4569, \\\\\n",
    "\\theta_3=(0.0937, 0.4475, 0.4459, 0.0127, 0.0002).\n",
    "\\end{equation}\n",
    "\n",
    "The true parameter for $\\beta$ is varied: $\\beta\\in \\{0.975, 0.985, 0.995, 0.999, 0.9995, 0.9999\\}$. For each $\\beta$ 250 data sets are simulated. Those are then estimated using five different starting values for the replacement cost $RC$ and the linear cost parameter $\\theta_{11}$. The following are the five different starting values: \n",
    "\n",
    "\\begin{align}\n",
    "(RC^0, \\theta^0_{11}) \\in \\{(4,1), (5,2), (6,3), (7,4), (8,5)\\}\n",
    "\\end{align}\n",
    "\n",
    "In the case of MPEC also starting values for the discretized expected value function are necessary and they are set to the zero vector every time: $EV^0_1,...,EV^0_{175}=(0,...,0)$. The subscript of 175 also displays the grid size that Iskhakov et al. choose to discretize the continuous variable of mileage. The starting values of the transition probabilities are frequency based in the paper and we follow this approach in our implementation.\n",
    "\n",
    "All those ingredients can be found below in the code. Further in our code for the NFXP we specify stopping criteria for the fixed point calculation as well as the tolerance at which we switch from contraction steps to Newton-Kantorovich (N-K) steps. Here, there is a first difference in our implementation of the NFXP as there is no switching back from N-K to contraction steps implemented. Furthermore the switching tolerance is solely an absolute one. For the routine to maximize the likelihood function we use the scipy L-BFGS-B povided by estimagic which uses a combination of relative and absolute stopping tolerance which also does not exactly match the original paper. Further the authors employ the BHHH algorithm instead of the L-BFGS-B which we will follow as well as soon as the algorithm is available on estimagic.\n",
    "\n",
    "\n",
    "For MPEC we could not rely on KNITRO as in the paper as it is not freely available. For the recreation of the table in Iskhakov et al. we decided to use nlopt here. Again the stopping tolerances cannot exactly be set to those of KNITRO in the paper. Another notable difference is that we only give analytical first order derivatives to nlopt. In the paper, on top of that second order analytical derivatives are provided by using automatic differentiation and also the sparsity patterns of both order derivatives are passed in. Apart from that, though, our setup replicates the paper by using upper and lower bounds as well as a properly recentering the expected value function. \n",
    "\n",
    "A last difference in our setup that affects both NFXP and MPEC is that we estimate the transition probabilities separately from the cost parameters. In the original paper for MPEC those are estimated jointly and for the NFXP the cost parameters are first estimated partially and then after that together with the transition probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity and comprehensibility, we decide to solely present the output for the discount factor $0.975$ paired with 100 simulation runs and only $(4, 1)$ as starting values for the cost parameter. This setup is selected below. But we also give the option to run the full simulation as done in Iskhakov et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_factor = [0.975]\n",
    "number_runs = 100\n",
    "starting_cost_params = np.array([[4], [1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the full simulation as described above, please uncomment the cell below and run it. The simulation then might take quite a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment and run this cell for a whole replication of Iskhakov et al. (2016)\n",
    "# discount_factor = [0.975, 0.985, 0.995, 0.999, 0.9995, 0.9999]\n",
    "# number_runs = 250\n",
    "# starting_cost_params = np.vstack((np.arange(4,9), np.arange(1,6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ruspy to run the estimation using either NFXP or MPEC we need to pass in a dictionairy plus the data to the function `get_criterion_function`. The cost parameters are estimated by minimizing the resulting criterion function using the `minimize` function of estimagic.\n",
    "Below we create one dictionairy per approach (NFXP or MPEC) and adapt it accordingly within the nested for-loop below depending on which discount factor $\\beta$ and which starting values are used in the respective run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "approach = [\"NFXP\", \"MPEC\"]\n",
    "starting_expected_value_fun = np.zeros(175)\n",
    "number_buses = 50\n",
    "number_periods = 120\n",
    "number_states = 175\n",
    "number_cost_params = 2\n",
    "scale = 1e-3\n",
    "\n",
    "# Initialize the set up for the nested fixed point algorithm\n",
    "stopping_crit_fixed_point = 1e-13\n",
    "switch_tolerance_fixed_point = 1e-2\n",
    "\n",
    "init_dict_nfxp = {\n",
    "    \"model_specifications\": {\n",
    "        \"num_states\": number_states,\n",
    "        \"maint_cost_func\": \"linear\",\n",
    "        \"cost_scale\": scale,\n",
    "    },\n",
    "    \"method\": \"NFXP\",\n",
    "    \"alg_details\": {\n",
    "        \"threshold\": stopping_crit_fixed_point,\n",
    "        \"switch_tol\": switch_tolerance_fixed_point,\n",
    "    },\n",
    "}\n",
    "\n",
    "init_dict_mpec = {\n",
    "    \"model_specifications\": {\n",
    "        \"num_states\": number_states,\n",
    "        \"maint_cost_func\": \"linear\",\n",
    "        \"cost_scale\": scale,\n",
    "    },\n",
    "    \"method\": \"MPEC\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrame to store the results of each run of the Monte Carlo simulation\n",
    "# does not store \"CPU Time\", \"# of Major Iter.\", \"# of Func. Eval.\", \"# of Bellm. Iter.\", \"# of N-K Iter.\"\n",
    "index = pd.MultiIndex.from_product(\n",
    "    [\n",
    "        discount_factor,\n",
    "        range(number_runs),\n",
    "        range(starting_cost_params.shape[1]),\n",
    "        approach,\n",
    "    ],\n",
    "    names=[\"Discount Factor\", \"Run\", \"Start\", \"Approach\"],\n",
    ")\n",
    "\n",
    "columns = [\n",
    "    \"RC\",\n",
    "    \"theta_11\",\n",
    "    \"theta_30\",\n",
    "    \"theta_31\",\n",
    "    \"theta_32\",\n",
    "    \"theta_33\",\n",
    "    \"Converged\",\n",
    "]\n",
    "\n",
    "results = pd.DataFrame(index=index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(123)\n",
    "\n",
    "saved_data = {}\n",
    "# Main loop to calculate the results for each run\n",
    "for factor in discount_factor:\n",
    "    saved_data[factor] = {}\n",
    "    # set up simulation of data\n",
    "    init_dict_simulation = {\n",
    "        \"simulation\": {\n",
    "            \"discount_factor\": factor,\n",
    "            \"periods\": number_periods,\n",
    "            \"buses\": number_buses,\n",
    "        },\n",
    "    }\n",
    "    params = np.array([11.7257, 2.4569])\n",
    "    trans_probs = np.array([0.0937, 0.4475, 0.4459, 0.0127, 0.0002])\n",
    "\n",
    "    # Calculate objects necessary for the simulation process. See documentation for details.\n",
    "    costs = calc_obs_costs(number_states, lin_cost, params, scale)\n",
    "    trans_mat = create_transition_matrix(number_states, trans_probs)\n",
    "    ev = calc_fixp(trans_mat, costs, factor)[0]\n",
    "\n",
    "    for run in range(number_runs):\n",
    "        # simulate the data\n",
    "        data = simulate(init_dict_simulation[\"simulation\"], ev, costs, trans_mat)\n",
    "        saved_data[factor][run] = data\n",
    "        for start in range(starting_cost_params.shape[1]):\n",
    "\n",
    "            init_params = starting_cost_params[:, start]\n",
    "\n",
    "            # Adapt the Initiation Dictionairy of NFXP for this run\n",
    "            init_dict_nfxp[\"model_specifications\"][\"discount_factor\"] = factor\n",
    "\n",
    "            # Run NFXP using ruspy and estimagic\n",
    "            function_dict_nfxp, transition_result_nfxp = get_criterion_function(\n",
    "                init_dict_nfxp, data\n",
    "            )\n",
    "\n",
    "            cost_result_nfxp = minimize(\n",
    "                criterion=function_dict_nfxp[\"criterion_function\"],\n",
    "                params=init_params,\n",
    "                algorithm=\"scipy_bfgs\",\n",
    "                derivative=function_dict_nfxp[\"criterion_derivative\"],\n",
    "            )\n",
    "            # convergence\n",
    "            status_nfxp = np.array([int(cost_result_nfxp.success)])\n",
    "\n",
    "            # store the results of this run\n",
    "            results.loc[factor, run, start, \"NFXP\"] = np.concatenate(\n",
    "                (cost_result_nfxp.params, transition_result_nfxp[\"x\"][:4], status_nfxp)\n",
    "            )\n",
    "\n",
    "            # Adapt the Initiation Dictionairy of MPEC for this run\n",
    "            init_dict_mpec[\"model_specifications\"][\"discount_factor\"] = factor\n",
    "\n",
    "            # Run MPEC using ruspy and estimagic\n",
    "            function_dict_mpec, result_transitions_mpec = get_criterion_function(\n",
    "                init_dict_mpec, data\n",
    "            )\n",
    "\n",
    "            cost_result_mpec = minimize(\n",
    "                criterion=function_dict_mpec[\"criterion_function\"],\n",
    "                params=np.concatenate((np.zeros(number_states), init_params)),\n",
    "                algorithm=\"nlopt_slsqp\",\n",
    "                derivative=function_dict_mpec[\"criterion_derivative\"],\n",
    "                constraints={\n",
    "                    \"type\": \"nonlinear\",\n",
    "                    \"func\": function_dict_mpec[\"constraint\"],\n",
    "                    \"derivative\": function_dict_mpec[\"constraint_derivative\"],\n",
    "                    \"value\": np.zeros(number_states, dtype=float),\n",
    "                },\n",
    "            )\n",
    "            # convergence\n",
    "            status_mpec = np.array([int(cost_result_mpec.success)])\n",
    "\n",
    "            # store the results of this run\n",
    "            results.loc[factor, run, start, \"MPEC\"] = np.concatenate(\n",
    "                (\n",
    "                    cost_result_mpec.params[number_states:],\n",
    "                    result_transitions_mpec[\"x\"][:4],\n",
    "                    status_mpec,\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give you an idea of what the above loop has just produced, let us have a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have actually relied on our own simulated data and do not use the one provided by Iskhakov et al., we calculate some some key statistics of theirs and ours to validate our simulated data and ensure that our results are actually comparrable to theirs. Some selected statistics are presented below for our simulated data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_simulated_data(saved_data, discount_factor, number_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is followed by the same statistics for the simulated data of Iskhakov et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\"check_simulated_data_iskhakov.pickle\").loc[discount_factor, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Table I from Su & Judd (2012)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed to Table I in Iskhakov et al., we give out the means and standard deviations of our parameter estimations like it was done by Su and Judd (2012) in Table I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Table I from Su & Judd (2012) with the simulated values from Iskahkov et al. (2016)\n",
    "columns_table_1 = [\"RC\", \"theta_11\", \"theta_30\", \"theta_31\", \"theta_32\", \"theta_33\"]\n",
    "table_1_temp = results.loc[results[\"Converged\"] == 1, columns_table_1].astype(float).groupby(\n",
    "    level=[\"Discount Factor\", \"Approach\"])\n",
    "\n",
    "statistic = [\"Mean\", \"Standard Deviation\"]\n",
    "index = pd.MultiIndex.from_product([discount_factor, approach, statistic],\n",
    "                                   names=[\"Discount Factor\", \"Approach\", \"Statistic\"])\n",
    "table_1 = pd.DataFrame(index=index, columns=columns_table_1)\n",
    "table_1.loc(axis=0)[:,:,\"Mean\"] = table_1_temp.mean()\n",
    "table_1.loc(axis=0)[:,:,\"Standard Deviation\"] = table_1_temp.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1.astype(float).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Corresponding (reduced) results from Iskhakov et al. (2016)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of the quality of our estimates, we compare this now to the results obtained by Iskhakov et al. using their original matlab code for the implementation of their NFXP. Those results were not published in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Table with the results \n",
    "index = pd.MultiIndex.from_product([discount_factor, statistic],\n",
    "                                   names=[\"Discount Factor\", \"Statistic\"])\n",
    "NFXP_Iskhakov = pd.DataFrame(index=index, columns=[\"RC\", \"theta_11\"])\n",
    "# load stored results\n",
    "results_iskhakov = pickle.load(open(\"results_iskhakov.pickle\", \"rb\"))\n",
    "for factor in discount_factor:\n",
    "    NFXP_Iskhakov_temp = results_iskhakov[factor]\n",
    "    NFXP_Iskhakov.loc[factor, \"Mean\"] = NFXP_Iskhakov_temp.mean(axis=0)\n",
    "    NFXP_Iskhakov.loc[factor, \"Standard Deviation\"] = NFXP_Iskhakov_temp.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFXP_Iskhakov.astype(float).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabler, J., \"A Python Tool for the Estimation of (Structural) Econometric Models.\", unpublished (2019), https://github.com/OpenSourceEconomics/estimagic\n",
    "\n",
    "Iskhakov, F., Lee, J., Rust, J., Schjerning, B. and Seo, K. (2016), Comment on “Constrained Optimization Approaches to Estimation of Structural Models”. Econometrica, 84: 365-370. doi:10.3982/ECTA12605\n",
    "\n",
    "Johnson, Steven G., The NLopt nonlinear-optimization package, http://github.com/stevengj/nlopt\n",
    "\n",
    "Rust, John. \"Optimal Replacement of GMC Bus Engines: An Empirical Model of Harold Zurcher.\" Econometrica 55, no. 5 (1987): 999-1033. Accessed June 7, 2020. doi:10.2307/1911259.\n",
    "\n",
    "Rust, John. \"Nested fixed point algorithm documentation manual.\" Unpublished Manuscript (6) (2000): 1-43.\n",
    "\n",
    "Su, C.‐L. and Judd, K.L. (2012), Constrained Optimization Approaches to Estimation of Structural Models. Econometrica, 80: 2213-2230. doi:10.3982/ECTA7925\n",
    "\n",
    "Wächter, A. and Biegler, L. T., On the Implementation of a Primal-Dual Interior Point Filter Line Search Algorithm for Large-Scale Nonlinear Programming, Mathematical Programming 106(1), pp. 25-57, 2006 (preprint), https://github.com/coin-or/Ipopt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
